


import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')





dictionary = {
    "Name": ["Anaya","Morris","Ayesha","Johnny","Katherine"],
    "Age": [24, 35, 12, 45, 20],
    "Driver": [True, True, False, np.nan, False]
}

data = pd.DataFrame(dictionary)
data.head(2)


data["EyesColor"] = ["Brown", "Black", "Blue", np.nan, "Green"]
data





url = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/titanic.csv'
df = pd.read_csv(url)
df.head()


df.shape


df.describe(include="all").round(2)


df.columns


df.info()





df.iloc[0]


df.iloc[:5]


df.iloc[1305::] # Last 8 records


df = df.set_index(df["Name"])
df.head()


df.loc["Allen, Miss Elisabeth Walton"]


df.iloc[0]








df = df.drop("Name", axis=1).reset_index()


df[df["Sex"] == "female"].head()


# There are 134 passengers who are female and the passenger class is 1st and who survived the disaster.
df[(df["Sex"] == "female") & (df["PClass"] == "1st") & (df["Survived"] == 1)].head()





df.sort_values(by=["Age","Sex"], ascending=False).head(4)





df["Sex"].replace("female","women", inplace=True)


df["Sex"].replace({"women": "Female", "male": "Male"}, inplace=True)


df.head()


df.replace(1, "One").head()


df.replace(r"1st", "First", regex=True).head()





df.rename(columns={"PClass": "Passenger Class", "Sex": "Gender"}, inplace=True)


df.head()





df["Age"].min()


df["Age"].max()


df["Age"].mean()


df["Age"].median()


df["Age"].sum()


df["Age"].count()


df.count()


df["Age"].std()


df["Age"].var()


# Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a 
# normal distribution.
df["Age"].kurt()


# Skewness is a measure of the asymmetry of a distribution.
df["Age"].skew()


# Standard error of mean means "how different the population mean is likely to be from a sample mean"
df["Age"].sem()





df.info()


df["Gender"].unique()


df["Passenger Class"].unique()


df.Gender.value_counts()


df["Passenger Class"].value_counts()


df["Age"].nunique()
# Number of unique values





df[df["Age"].isna()].shape
# Total 557 Records do not have the age mentioned.


df[df["Age"].isna()].fillna(df["Age"].median()).head()





df.drop(["Gender"], axis=1).head()
# By default the method returns the copy of the dataframe until and unless the
# parameter inplace is set to True.


df.drop(["SexCode"], axis=1, inplace=True)


df.drop([df.columns[0]], axis=1).head()
# Columns can also be dropped using index position if the column name is not mentioned.





df.drop(df[df["Gender"] != "Male"].index.tolist()).head()


df.drop([0, 1, 2, 3, 4, 5], axis = 0).head(2)





df.drop_duplicates().head(2)


df.drop_duplicates(subset = ["Name"]).tail()
# Dropping the rows with duplicate names.


df.duplicated()





df.head(3)


df.groupby("Passenger Class").mean(["Age", "Survived"])


df.groupby("Survived")["Name"].count()


df.groupby(["Gender","Survived"]).mean(["Age"])





time_index = pd.date_range("06/06/2017", periods = 100000, freq = "30s")
time_index


data = pd.DataFrame(index = time_index)


data["Sale_Amount"] = np.random.randint(1, 10, 100000)


data.head()


# Group the rows by week, and calculate the sum per week
data.resample('W').sum()


data.resample("2W").mean()
# Group by 2 weeks and calculate the mean


data.resample("M").count()


data.resample("M", label = "left").count()





url = 'https://raw.githubusercontent.com/chrisalbon/sim_data/master/titanic.csv'
df = pd.read_csv(url)
df.head()


df.agg("min")


df.agg({"Age": ["min", "max", "mean"], "SexCode": ["min", "max"]})


df.groupby(["PClass", "Survived"]).agg({"Survived": ["count"]}).reset_index()





for name in df["Name"][:5]:
    print(name.upper())


[name.upper() for name in df["Name"][:5]]





def uppercase(x):
    return x.upper()

df["Name"].apply(uppercase)[:5]





# here, "x" represents the individual group.
df.groupby("Sex").apply(lambda x : x.count())





dictionary = {
    "Name": ["Anaya","Morris","Ayesha","Johnny","Katherine"],
    "Age": [24, 35, 12, 45, 20],
    "Driver": [True, True, False, np.nan, False]
}
data_a = pd.DataFrame(dictionary)

dictionary = {
    "Name": ["Anu", "Meghna", "Shaima"],
    "Age": [59, 45, 25],
    "Driver": [True, True, False]
}
data_b = pd.DataFrame(dictionary)


df2 = pd.concat([data_a, data_b], axis = 0).reset_index().drop(["index"], axis = 1)
# Stacking the data vertically

df2.head()





emp_data = {
    "id": [1, 2, 3, 4, 5],
    "name": ["Amy Jones", "Catherine", "Arjun Roy", "Alice", "Kim Jung"] 
}
df_emp = pd.DataFrame(emp_data)

sales_data = {
    "id": [3, 4, 5, 6, 7, 8],
    "tot_sales": [1234, 5262, 9821, 2756, 5123, 6789]
}
df_sales = pd.DataFrame(sales_data)


pd.merge(df_emp, df_sales, on = "id", how = "inner")


pd.merge(df_emp, df_sales, on = "id", how = "left")


pd.merge(df_emp, df_sales, on = "id", how = "right")


pd.merge(df_emp, df_sales, on = "id", how = "outer")






